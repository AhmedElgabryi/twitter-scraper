{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter scraper",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP62gm1rzpeVpld/F0C+vW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedElgabryi/twitter-scraper/blob/master/twitter_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DypqgFzeSekI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from selenium import webdriver\n",
        "from datetime import date, timedelta\n",
        "import time\n",
        "import logging\n",
        "import argparse\n",
        "\n",
        "log = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def scrape_loop(screen_name, since_date=date(2011, 4, 5), until_date=date.today(), delta_days=30, include_retweets=True,\n",
        "                wait_secs=5):\n",
        "    tweet_ids = set()\n",
        "    for new_since_date, new_until_date in _next_dates(since_date, until_date, delta_days):\n",
        "        new_tweet_ids = scrape(screen_name, new_since_date, new_until_date, include_retweets=include_retweets,\n",
        "                               wait_secs=wait_secs)\n",
        "        tweet_ids.update(new_tweet_ids)\n",
        "        log.info(\"Found %s tweet ids for a total of %s unique tweet ids\", len(new_tweet_ids), len(tweet_ids))\n",
        "    return tweet_ids\n",
        "\n",
        "\n",
        "def _next_dates(since_date, until_date, delta_days):\n",
        "    last_date = False\n",
        "    new_since_date = until_date\n",
        "    while not last_date:\n",
        "        new_until_date = new_since_date\n",
        "        new_since_date = new_since_date - timedelta(days=delta_days)\n",
        "        if new_since_date <= since_date:\n",
        "            new_since_date = since_date\n",
        "            last_date = True\n",
        "        yield new_since_date, new_until_date\n",
        "\n",
        "\n",
        "def scrape(screen_name, since_date, until_date, include_retweets=True, wait_secs=5):\n",
        "    log.info(\"Scraping %s since %s until %s\", screen_name, since_date, until_date)\n",
        "    driver = webdriver.Chrome()\n",
        "    try:\n",
        "        driver.implicitly_wait(wait_secs)\n",
        "        url = \"https://twitter.com/search?f=tweets&vertical=default&q=from:{}+since:{}+until:{}&src=typd\".format(screen_name, since_date.isoformat(),\n",
        "                                                                              until_date.isoformat())\n",
        "        if include_retweets:\n",
        "            url += \"+include:retweets\"\n",
        "        log.debug(\"Getting %s\", url)\n",
        "        driver.get(url)\n",
        "\n",
        "        scroll_count = 0\n",
        "        last_tweet_count = 0\n",
        "        while last_tweet_count != len(driver.find_elements_by_class_name(\"original-tweet\")):\n",
        "            scroll_count += 1\n",
        "            last_tweet_count = len(driver.find_elements_by_class_name(\"original-tweet\"))\n",
        "            log.debug(\"Scrolling down %s. Found %s tweets.\", scroll_count, last_tweet_count)\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(wait_secs)\n",
        "\n",
        "        return set([e.get_attribute(\"data-tweet-id\") for e in driver.find_elements_by_class_name(\"original-tweet\")])\n",
        "    finally:\n",
        "        driver.close()\n",
        "        driver.quit()\n",
        "\n",
        "\n",
        "def _to_date(date_str):\n",
        "    date_split = date_str.split(\"-\")\n",
        "    return date(int(date_split[0]), int(date_split[1]), int(date_split[2]))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"screen_name\")\n",
        "    parser.add_argument(\"--since\", default=\"2011-04-05\", help=\"Tweets since this date. Default is 2011-04-05.\")\n",
        "    parser.add_argument(\"--until\", default=date.today().isoformat(), help=\"Tweets until this date. Default is today.\")\n",
        "    parser.add_argument(\"--exclude-retweets\", action=\"store_false\")\n",
        "    parser.add_argument(\"--delta-days\", type=int, default=30, help=\"Number of days to include in each search.\")\n",
        "    parser.add_argument(\"--wait-secs\", type=int, default=5, help=\"Number of seconds to wait between each scroll.\")\n",
        "    parser.add_argument(\"--debug\", action=\"store_true\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "                        level=logging.DEBUG if args.debug else logging.INFO)\n",
        "    logging.getLogger(\"selenium\").setLevel(logging.WARNING)\n",
        "\n",
        "    main_tweet_ids = scrape_loop(args.screen_name, _to_date(args.since), _to_date(args.until),\n",
        "                                 include_retweets=args.exclude_retweets, delta_days=args.delta_days,\n",
        "                                 wait_secs=args.wait_secs)\n",
        "    for tweet_id in main_tweet_ids:\n",
        "        print(tweet_id)\n",
        "    log.info(\"Found %s unique tweet ids\", len(main_tweet_ids))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORQlp3T4ZF5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}